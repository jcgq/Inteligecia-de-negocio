{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from statistics import mode\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Todas las librerías para los distintos algoritmos\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import statistics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from pylab import rcParams\n",
    " \n",
    "from collections import Counter\n",
    "\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train= pd.read_csv(\"./datos/train.csv\",na_values=[\"?\"])\n",
    "data_test= pd.read_csv(\"./datos/test.csv\",na_values=[\"?\"])\n",
    "data_trainCopia = data_train.copy()\n",
    "data_testCopia = data_test.copy()\n",
    "Nombre = LabelEncoder().fit(pd.read_csv(\"./datos/nombre.csv\").Nombre)\n",
    "Año = LabelEncoder().fit(pd.read_csv(\"./datos/ao.csv\").Año)\n",
    "Ciudad = LabelEncoder().fit(pd.read_csv(\"./datos/ciudad.csv\").Ciudad)\n",
    "Combustible = LabelEncoder().fit(pd.read_csv(\"./datos/combustible.csv\").Combustible)\n",
    "Consumo = LabelEncoder().fit(pd.read_csv(\"./datos/consumo.csv\").Consumo)\n",
    "Descuento = LabelEncoder().fit(pd.read_csv(\"./datos/descuento.csv\").Descuento)\n",
    "Kilometros = LabelEncoder().fit(pd.read_csv(\"./datos/kilometros.csv\").Kilometros)\n",
    "Mano = LabelEncoder().fit(pd.read_csv(\"./datos/mano.csv\").Mano)\n",
    "Potencia = LabelEncoder().fit(pd.read_csv(\"./datos/potencia.csv\").Potencia)\n",
    "Asientos = LabelEncoder().fit(pd.read_csv(\"./datos/asientos.csv\").Asientos)\n",
    "Motor_CC=LabelEncoder().fit(pd.read_csv(\"./datos/motor_cc.csv\").Motor_CC)\n",
    "Tipo_marchas=LabelEncoder().fit(pd.read_csv(\"./datos/Tipo_marchas.csv\").Tipo_marchas)\n",
    "\n",
    "data_trainCopia['Nombre']=data_trainCopia['Nombre'].fillna(mode(data_trainCopia['Nombre']))\n",
    "data_trainCopia['Año']=data_trainCopia['Año'].fillna(mode(data_trainCopia['Año']))\n",
    "data_trainCopia['Ciudad']=data_trainCopia['Ciudad'].fillna(mode(data_trainCopia['Ciudad']))\n",
    "#data_trainCopia['Kilometros']=data_trainCopia['Kilometros'].fillna(mode(data_trainCopia['Kilometros']))\n",
    "data_trainCopia['Combustible']=data_trainCopia['Combustible'].fillna(mode(data_trainCopia['Combustible']))\n",
    "data_trainCopia['Tipo_marchas']=data_trainCopia['Tipo_marchas'].fillna(mode(data_trainCopia['Tipo_marchas']))\n",
    "data_trainCopia['Mano']=data_trainCopia['Mano'].fillna(mode(data_trainCopia['Mano']))\n",
    "data_trainCopia['Consumo']=data_trainCopia['Consumo'].fillna(mode(data_trainCopia['Consumo']))\n",
    "data_trainCopia['Motor_CC']=data_trainCopia['Motor_CC'].fillna(mode(data_trainCopia['Motor_CC']))\n",
    "data_trainCopia['Potencia']=data_trainCopia['Potencia'].fillna(mode(data_trainCopia['Potencia']))\n",
    "data_trainCopia['Asientos']=data_trainCopia['Asientos'].fillna(mode(data_trainCopia['Asientos']))\n",
    "data_trainCopia['Descuento']=data_trainCopia['Descuento'].fillna(mode(data_trainCopia['Descuento']))\n",
    "\n",
    "#Eliminamos las columnas que no necesitamos\n",
    "data_trainCopia=data_trainCopia.drop(['Descuento'], axis=1)\n",
    "data_trainCopia=data_trainCopia.drop(['id'], axis=1)\n",
    "data_trainCopia=data_trainCopia.drop(['Kilometros'], axis=1)\n",
    "data_testCopia=data_testCopia.drop(['Descuento'], axis=1)\n",
    "data_testCopia=data_testCopia.drop(['id'], axis=1)\n",
    "data_testCopia=data_testCopia.drop(['Kilometros'], axis=1)\n",
    "\n",
    "#Eliminamos los nan de los ids\n",
    "data_trainCopia=data_trainCopia.dropna() \n",
    "data_testCopia=data_testCopia.dropna() \n",
    "\n",
    "#Codificación de las filas\n",
    "data_trainCopia.Nombre = Nombre.transform(data_trainCopia.Nombre)\n",
    "data_trainCopia.Año = Año.transform(data_trainCopia.Año)\n",
    "data_trainCopia.Ciudad = Ciudad.transform(data_trainCopia.Ciudad)\n",
    "data_trainCopia.Combustible = Combustible.transform(data_trainCopia.Combustible)\n",
    "data_trainCopia.Potencia = Potencia.transform(data_trainCopia.Potencia)\n",
    "data_trainCopia.Consumo = Consumo.transform(data_trainCopia.Consumo)\n",
    "data_trainCopia.Kilometros = Kilometros.transform(data_trainCopia.Kilometros)\n",
    "data_trainCopia.Mano = Mano.transform(data_trainCopia.Mano)\n",
    "data_trainCopia.Motor_CC = Motor_CC.transform(data_trainCopia.Motor_CC)\n",
    "data_trainCopia.Tipo_marchas = Tipo_marchas.transform(data_trainCopia.Tipo_marchas)\n",
    "data_trainCopia.Asientos = Asientos.transform(data_trainCopia.Asientos)\n",
    "#-------------------------------------------------------------------------------------------\n",
    "data_testCopia.Nombre = Nombre.transform(data_testCopia.Nombre)\n",
    "data_testCopia.Año = Año.transform(data_testCopia.Año)\n",
    "data_testCopia.Ciudad = Ciudad.transform(data_testCopia.Ciudad)\n",
    "data_testCopia.Combustible = Combustible.transform(data_testCopia.Combustible)\n",
    "data_testCopia.Potencia = Potencia.transform(data_testCopia.Potencia)\n",
    "data_testCopia.Consumo = Consumo.transform(data_testCopia.Consumo)\n",
    "data_testCopia.Kilometros = Kilometros.transform(data_testCopia.Kilometros)\n",
    "data_testCopia.Mano = Mano.transform(data_testCopia.Mano)\n",
    "data_testCopia.Tipo_marchas = Tipo_marchas.transform(data_testCopia.Tipo_marchas)\n",
    "data_testCopia.Asientos = Asientos.transform(data_testCopia.Asientos)\n",
    "data_testCopia.Motor_CC = Motor_CC.transform(data_testCopia.Motor_CC)\n",
    "\n",
    "target = pd.read_csv('./datos/precio_cat.csv')\n",
    "target_train=data_trainCopia['Precio_cat']\n",
    "data_trainCopia=data_trainCopia.drop(['Precio_cat'], axis=1)\n",
    "data_trainCopia=data_trainCopia.astype(float)\n",
    "data_testCopia=data_testCopia.astype(float)\n",
    "\n",
    "data_testCopia_nor = (data_testCopia-data_trainCopia.mean(0))/data_trainCopia.std(0)\n",
    "data_trainCopia_nor = (data_trainCopia-data_trainCopia.mean(0))/data_trainCopia.std(0)\n",
    "\n",
    "atributos=data_trainCopia_nor[['Nombre','Ciudad', 'Año', 'Kilometros', 'Combustible','Tipo_marchas','Mano','Consumo','Motor_CC','Potencia', 'Asientos']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada CON MODELO 82.53672009317286\n"
     ]
    }
   ],
   "source": [
    "#Sin normalizar los datos y con los parametros con los que conseguí la mejora 0.79986\n",
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.055, objective='binary', n_estimators=640, n_jobs=2, \n",
    "                          num_leaves=20, max_depth=-1,seed=46000)\n",
    "\n",
    "scores = cross_val_score(lgbm1, data_trainCopia, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada CON MODELO\", np.mean(scores)*100)\n",
    "\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia, target_train)\n",
    "preLgbOVER = lgbmEntrenado.predict(data_testCopia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada CON MODELO 82.34684709666683\n"
     ]
    }
   ],
   "source": [
    "#Normalizar los datos y con la segunda subida 0.79986\n",
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.055, objective='binary', n_estimators=640, n_jobs=2, \n",
    "                          num_leaves=20, max_depth=-1,seed=46000)\n",
    "\n",
    "scores = cross_val_score(lgbm1, data_trainCopia_nor, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada CON MODELO\", np.mean(scores)*100)\n",
    "\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia_nor, target_train)\n",
    "preLgbOVER = lgbmEntrenado.predict(data_testCopia_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada CON MODELO 83.44240474737951\n"
     ]
    }
   ],
   "source": [
    "#Sin normalizar los datos y con la primera subida 0.79896\n",
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.055, objective='binary', n_estimators=460, n_jobs=2, \n",
    "                          num_leaves=10, max_depth=-1,seed=46000, reg_alpha=0.1)\n",
    "\n",
    "scores = cross_val_score(lgbm1, data_trainCopia, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada CON MODELO\", np.mean(scores)*100)\n",
    "\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia, target_train)\n",
    "preLgbOVER = lgbmEntrenado.predict(data_testCopia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada CON MODELO 83.75850479729354\n"
     ]
    }
   ],
   "source": [
    "#PROBANDO A LAS 16.38 CON MI MADRE EL 30 DE DICIEMBRE\n",
    "#Sin normalizar los datos y con la primera subida 0.79896\n",
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.055, objective='binary', n_estimators=450, n_jobs=2, \n",
    "                          num_leaves=11, max_depth=-1, reg_alpha=0.1)\n",
    "\n",
    "scores = cross_val_score(lgbm1, data_trainCopia, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada CON MODELO\", np.mean(scores)*100)\n",
    "\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia, target_train)\n",
    "preLgbOVER = lgbmEntrenado.predict(data_testCopia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada CON MODELO 83.06319117076146\n"
     ]
    }
   ],
   "source": [
    "#Normalizar los datos y con la primera subida 0.79896\n",
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.055, objective='binary', n_estimators=450, n_jobs=2, \n",
    "                          num_leaves=12, max_depth=-1,seed=46000, reg_alpha=0.1)\n",
    "\n",
    "scores = cross_val_score(lgbm1, data_trainCopia_nor, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada CON MODELO\", np.mean(scores)*100)\n",
    "\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia_nor, target_train)\n",
    "preLgbOVER = lgbmEntrenado.predict(data_testCopia_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAux = pd.DataFrame({'id':data_test['id']})\n",
    "dfAux.set_index('id', inplace=True)\n",
    "dfFinal = pd.DataFrame({'id': data_test['id'], 'Precio_cat': preLgbOVER}, columns=['id', 'Precio_cat'])\n",
    "dfFinal.set_index('id', inplace=True)\n",
    "dfFinal.to_csv(\"./soluciones/basura.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada CON MODELO 83.77960179690534\n"
     ]
    }
   ],
   "source": [
    "#Subida 49\n",
    "#PROBANDO A LAS 16.38 CON MI MADRE EL 30 DE DICIEMBRE definitivo: Será mi primer intento\n",
    "#Sin normalizar los datos y con la primera subida 0.79896\n",
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.055, objective='binary', n_estimators=440, n_jobs=2, \n",
    "                          num_leaves=11, max_depth=-1, reg_alpha=0.1)\n",
    "\n",
    "scores = cross_val_score(lgbm1, data_trainCopia, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada CON MODELO\", np.mean(scores)*100)\n",
    "\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia, target_train)\n",
    "preMamaJuanca = lgbmEntrenado.predict(data_testCopia)\n",
    "\n",
    "dfAux = pd.DataFrame({'id':data_test['id']})\n",
    "dfAux.set_index('id', inplace=True)\n",
    "dfFinal = pd.DataFrame({'id': data_test['id'], 'Precio_cat': preMamaJuanca}, columns=['id', 'Precio_cat'])\n",
    "dfFinal.set_index('id', inplace=True)\n",
    "dfFinal.to_csv(\"./soluciones/LGBM31DiciembreScore837796SinNormalizarDatos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada CON MODELO 83.4212633797349\n"
     ]
    }
   ],
   "source": [
    "#Subida 50\n",
    "#PROBANDO A LAS 16.57 CON MI MADRE EL 30 DE DICIEMBRE definitivo: Será mi segundo intento\n",
    "#Normalizar los datos y con la primera subida 0.79896\n",
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.055, objective='binary', n_estimators=440, n_jobs=2, \n",
    "                          num_leaves=12, max_depth=-1,seed=46000, reg_alpha=0.9)\n",
    "\n",
    "scores = cross_val_score(lgbm1, data_trainCopia_nor, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada CON MODELO\", np.mean(scores)*100)\n",
    "\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia_nor, target_train)\n",
    "preLgbOVER_ul = lgbmEntrenado.predict(data_testCopia_nor)\n",
    "\n",
    "dfAux = pd.DataFrame({'id':data_test['id']})\n",
    "dfAux.set_index('id', inplace=True)\n",
    "dfFinal = pd.DataFrame({'id': data_test['id'], 'Precio_cat': preLgbOVER_ul}, columns=['id', 'Precio_cat'])\n",
    "dfFinal.set_index('id', inplace=True)\n",
    "dfFinal.to_csv(\"./soluciones/LGBM31DiciembreScore834212CONNormalizacionDatos.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from statistics import mode\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Todas las librerías para los distintos algoritmos\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import statistics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "from pylab import rcParams\n",
    "from sklearn import impute\n",
    " \n",
    "from collections import Counter\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train= pd.read_csv(\"./datos/train.csv\",na_values=[\"?\"])\n",
    "data_test= pd.read_csv(\"./datos/test.csv\",na_values=[\"?\"])\n",
    "data_trainCopia = data_train.copy()\n",
    "data_testCopia = data_test.copy()\n",
    "\n",
    "Nombre = LabelEncoder().fit(pd.read_csv(\"./datos/nombre.csv\").Nombre)\n",
    "Año = LabelEncoder().fit(pd.read_csv(\"./datos/ao.csv\").Año)\n",
    "Ciudad = LabelEncoder().fit(pd.read_csv(\"./datos/ciudad.csv\").Ciudad)\n",
    "Combustible = LabelEncoder().fit(pd.read_csv(\"./datos/combustible.csv\").Combustible)\n",
    "Consumo = LabelEncoder().fit(pd.read_csv(\"./datos/consumo.csv\").Consumo)\n",
    "Kilometros = LabelEncoder().fit(pd.read_csv(\"./datos/kilometros.csv\").Kilometros)\n",
    "Mano = LabelEncoder().fit(pd.read_csv(\"./datos/mano.csv\").Mano)\n",
    "Potencia = LabelEncoder().fit(pd.read_csv(\"./datos/potencia.csv\").Potencia)\n",
    "Asientos = LabelEncoder().fit(pd.read_csv(\"./datos/asientos.csv\").Asientos)\n",
    "Motor_CC=LabelEncoder().fit(pd.read_csv(\"./datos/motor_cc.csv\").Motor_CC)\n",
    "Tipo_marchas=LabelEncoder().fit(pd.read_csv(\"./datos/Tipo_marchas.csv\").Tipo_marchas)\n",
    "\n",
    "data_trainCopia['Nombre']=data_trainCopia['Nombre'].fillna(mode(data_trainCopia['Nombre']))\n",
    "data_trainCopia['Año']=data_trainCopia['Año'].fillna(mode(data_trainCopia['Año']))\n",
    "data_trainCopia['Ciudad']=data_trainCopia['Ciudad'].fillna(mode(data_trainCopia['Ciudad']))\n",
    "data_trainCopia['Kilometros']=data_trainCopia['Kilometros'].fillna(mode(data_trainCopia['Kilometros']))\n",
    "data_trainCopia['Combustible']=data_trainCopia['Combustible'].fillna(mode(data_trainCopia['Combustible']))\n",
    "data_trainCopia['Tipo_marchas']=data_trainCopia['Tipo_marchas'].fillna(mode(data_trainCopia['Tipo_marchas']))\n",
    "data_trainCopia['Mano']=data_trainCopia['Mano'].fillna(mode(data_trainCopia['Mano']))\n",
    "data_trainCopia['Consumo']=data_trainCopia['Consumo'].fillna(mode(data_trainCopia['Consumo']))\n",
    "data_trainCopia['Motor_CC']=data_trainCopia['Motor_CC'].fillna(mode(data_trainCopia['Motor_CC']))\n",
    "data_trainCopia['Potencia']=data_trainCopia['Potencia'].fillna(mode(data_trainCopia['Potencia']))\n",
    "data_trainCopia['Asientos']=data_trainCopia['Asientos'].fillna(mode(data_trainCopia['Asientos']))\n",
    "\n",
    "\n",
    "#Eliminamos las columnas que no necesitamos\n",
    "data_trainCopia=data_trainCopia.drop(['Descuento'], axis=1)\n",
    "data_trainCopia=data_trainCopia.drop(['id'], axis=1)\n",
    "data_testCopia=data_testCopia.drop(['Descuento'], axis=1)\n",
    "data_testCopia=data_testCopia.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "#Eliminamos los nan de los ids\n",
    "data_trainCopia=data_trainCopia.dropna() \n",
    "data_testCopia=data_testCopia.dropna() \n",
    "\n",
    "#Codificación de las filas\n",
    "data_trainCopia.Nombre = Nombre.transform(data_trainCopia.Nombre)\n",
    "data_trainCopia.Año = Año.transform(data_trainCopia.Año)\n",
    "data_trainCopia.Ciudad = Ciudad.transform(data_trainCopia.Ciudad)\n",
    "data_trainCopia.Combustible = Combustible.transform(data_trainCopia.Combustible)\n",
    "data_trainCopia.Potencia = Potencia.transform(data_trainCopia.Potencia)\n",
    "data_trainCopia.Consumo = Consumo.transform(data_trainCopia.Consumo)\n",
    "data_trainCopia.Kilometros = Kilometros.transform(data_trainCopia.Kilometros)\n",
    "data_trainCopia.Mano = Mano.transform(data_trainCopia.Mano)\n",
    "data_trainCopia.Motor_CC = Motor_CC.transform(data_trainCopia.Motor_CC)\n",
    "data_trainCopia.Tipo_marchas = Tipo_marchas.transform(data_trainCopia.Tipo_marchas)\n",
    "data_trainCopia.Asientos = Asientos.transform(data_trainCopia.Asientos)\n",
    "#-------------------------------------------------------------------------------------------\n",
    "data_testCopia.Nombre = Nombre.transform(data_testCopia.Nombre)\n",
    "data_testCopia.Año = Año.transform(data_testCopia.Año)\n",
    "data_testCopia.Ciudad = Ciudad.transform(data_testCopia.Ciudad)\n",
    "data_testCopia.Combustible = Combustible.transform(data_testCopia.Combustible)\n",
    "data_testCopia.Potencia = Potencia.transform(data_testCopia.Potencia)\n",
    "data_testCopia.Consumo = Consumo.transform(data_testCopia.Consumo)\n",
    "data_testCopia.Kilometros = Kilometros.transform(data_testCopia.Kilometros)\n",
    "data_testCopia.Mano = Mano.transform(data_testCopia.Mano)\n",
    "data_testCopia.Tipo_marchas = Tipo_marchas.transform(data_testCopia.Tipo_marchas)\n",
    "data_testCopia.Asientos = Asientos.transform(data_testCopia.Asientos)\n",
    "data_testCopia.Motor_CC = Motor_CC.transform(data_testCopia.Motor_CC)\n",
    "\n",
    "\n",
    "#Obtener el resto de los atributos\n",
    "target_train=data_trainCopia['Precio_cat']\n",
    "data_trainCopia=data_trainCopia.drop(['Precio_cat'], axis=1)\n",
    "atributos=data_trainCopia[['Nombre','Ciudad', 'Año','Kilometros','Combustible','Tipo_marchas','Mano','Consumo','Motor_CC','Potencia', 'Asientos']]\n",
    "target = pd.read_csv('./datos/precio_cat.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "Score Validacion Cruzada 82.74713548888026\n"
     ]
    }
   ],
   "source": [
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.25, objective='binary', n_estimators=300, n_jobs=2, \n",
    "                          num_leaves=65, max_depth=2, min_data_in_leaf=90)\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia, target_train)\n",
    "preLgb = lgbmEntrenado.predict(data_testCopia)\n",
    "\n",
    "scores = cross_val_score(lgbmEntrenado, atributos, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada\", np.mean(scores)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada CON MODELO 83.08433253840607\n",
      "Score Validacion Cruzada CON MODELO 83.08433253840607\n"
     ]
    }
   ],
   "source": [
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.055, objective='regression_l1', n_estimators=850, n_jobs=2, \n",
    "                          num_leaves=10, max_depth=-1)\n",
    "\n",
    "scores = cross_val_score(lgbm1, data_trainCopia, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada CON MODELO\", np.mean(scores)*100)\n",
    "\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia, target_train)\n",
    "preLgb = lgbmEntrenado.predict(data_testCopia)\n",
    "\n",
    "scores = cross_val_score(lgbmEntrenado, atributos, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada CON MODELO\", np.mean(scores)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada 74.95712938827575\n"
     ]
    }
   ],
   "source": [
    "classifier1 = lgb.LGBMClassifier(learning_rate=0.055, objective='binary', n_estimators=460, n_jobs=2, \n",
    "                          num_leaves=10, max_depth=-1,seed=46000)\n",
    "classifier2 = GradientBoostingClassifier(learning_rate = 0.1, min_samples_split = 500, min_samples_leaf = 50, \n",
    "                                         max_depth = 8, max_features = 'sqrt', subsample = 0.8, random_state = 10)\n",
    "\n",
    "clf = StackingCVClassifier(classifiers = [classifier1, classifier2],\n",
    "                            shuffle = False,\n",
    "                            use_probas = True,\n",
    "                            cv = 5, meta_classifier = SVC(probability = True))\n",
    "    \n",
    "stakingModelo = clf.fit(data_trainCopia, target_train)\n",
    "preStaking = stakingModelo.predict(data_testCopia)\n",
    "\n",
    "scores = cross_val_score(lgbmEntrenado, atributos, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada\", np.mean(scores)*100)\n",
    "\n",
    "dfAux = pd.DataFrame({'id':data_test['id']})\n",
    "dfAux.set_index('id', inplace=True)\n",
    "dfFinal = pd.DataFrame({'id': data_test['id'], 'Precio_cat': stakingModelo}, columns=['id', 'Precio_cat'])\n",
    "dfFinal.set_index('id', inplace=True)\n",
    "dfFinal.to_csv(\"./soluciones/stakingGradienLgbm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada 83.37931340469191\n"
     ]
    }
   ],
   "source": [
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.055, objective='binary', n_estimators=460, n_jobs=2, \n",
    "                          num_leaves=10, max_depth=-1,seed=46000)\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia, target_train)\n",
    "preLgb = lgbmEntrenado.predict(data_testCopia)\n",
    "\n",
    "scores = cross_val_score(lgbmEntrenado, atributos, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada\", np.mean(scores)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada 83.147601353225\n"
     ]
    }
   ],
   "source": [
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.055, objective='binary', n_estimators=460, n_jobs=2, \n",
    "                          num_leaves=10, max_depth=-1,seed=46000)\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia, target_train)\n",
    "preLgb = lgbmEntrenado.predict(data_testCopia)\n",
    "\n",
    "scores = cross_val_score(lgbmEntrenado, atributos, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada\", np.mean(scores)*100)\n",
    "recall_score(target_train, preLgb, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:30:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:30:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:31:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:31:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:31:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:31:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Score Validacion Cruzada 82.07309633409128\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "clf = xgb.XGBClassifier(max_depth=10, n_estimators = 1000, learning_rate=0.05, n_jobs=-1)\n",
    "clfEntrenado = clf.fit(data_trainCopia, target_train)\n",
    "preclf = clfEntrenado.predict(data_testCopia)\n",
    "\n",
    "scores = cross_val_score(clfEntrenado, atributos, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada\", np.mean(scores)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAux = pd.DataFrame({'id':data_test['id']})\n",
    "dfAux.set_index('id', inplace=True)\n",
    "dfFinal = pd.DataFrame({'id': data_test['id'], 'Precio_cat': preLgb}, columns=['id', 'Precio_cat'])\n",
    "dfFinal.set_index('id', inplace=True)\n",
    "dfFinal.to_csv(\"./soluciones/solucionNOCHE16.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

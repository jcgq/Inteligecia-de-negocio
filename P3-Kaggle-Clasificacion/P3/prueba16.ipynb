{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from statistics import mode\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Todas las librerías para los distintos algoritmos\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import statistics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from pylab import rcParams\n",
    " \n",
    "from collections import Counter\n",
    "\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train= pd.read_csv(\"./datos/train.csv\",na_values=[\"?\"])\n",
    "data_test= pd.read_csv(\"./datos/test.csv\",na_values=[\"?\"])\n",
    "data_trainCopia = data_train.copy()\n",
    "data_testCopia = data_test.copy()\n",
    "Nombre = LabelEncoder().fit(pd.read_csv(\"./datos/nombre.csv\").Nombre)\n",
    "Año = LabelEncoder().fit(pd.read_csv(\"./datos/ao.csv\").Año)\n",
    "Ciudad = LabelEncoder().fit(pd.read_csv(\"./datos/ciudad.csv\").Ciudad)\n",
    "Combustible = LabelEncoder().fit(pd.read_csv(\"./datos/combustible.csv\").Combustible)\n",
    "Consumo = LabelEncoder().fit(pd.read_csv(\"./datos/consumo.csv\").Consumo)\n",
    "Descuento = LabelEncoder().fit(pd.read_csv(\"./datos/descuento.csv\").Descuento)\n",
    "Kilometros = LabelEncoder().fit(pd.read_csv(\"./datos/kilometros.csv\").Kilometros)\n",
    "Mano = LabelEncoder().fit(pd.read_csv(\"./datos/mano.csv\").Mano)\n",
    "Potencia = LabelEncoder().fit(pd.read_csv(\"./datos/potencia.csv\").Potencia)\n",
    "Asientos = LabelEncoder().fit(pd.read_csv(\"./datos/asientos.csv\").Asientos)\n",
    "Motor_CC=LabelEncoder().fit(pd.read_csv(\"./datos/motor_cc.csv\").Motor_CC)\n",
    "\n",
    "data_trainCopia['Nombre']=data_trainCopia['Nombre'].fillna(mode(data_trainCopia['Nombre']))\n",
    "data_trainCopia['Año']=data_trainCopia['Año'].fillna(mode(data_trainCopia['Año']))\n",
    "data_trainCopia['Ciudad']=data_trainCopia['Ciudad'].fillna(mode(data_trainCopia['Ciudad']))\n",
    "data_trainCopia['Kilometros']=data_trainCopia['Kilometros'].fillna(mode(data_trainCopia['Kilometros']))\n",
    "data_trainCopia['Combustible']=data_trainCopia['Combustible'].fillna(mode(data_trainCopia['Combustible']))\n",
    "data_trainCopia['Tipo_marchas']=data_trainCopia['Tipo_marchas'].fillna(mode(data_trainCopia['Tipo_marchas']))\n",
    "data_trainCopia['Mano']=data_trainCopia['Mano'].fillna(mode(data_trainCopia['Mano']))\n",
    "data_trainCopia['Consumo']=data_trainCopia['Consumo'].fillna(mode(data_trainCopia['Consumo']))\n",
    "data_trainCopia['Motor_CC']=data_trainCopia['Motor_CC'].fillna(mode(data_trainCopia['Motor_CC']))\n",
    "data_trainCopia['Potencia']=data_trainCopia['Potencia'].fillna(mode(data_trainCopia['Potencia']))\n",
    "data_trainCopia['Asientos']=data_trainCopia['Asientos'].fillna(mode(data_trainCopia['Asientos']))\n",
    "data_trainCopia['Descuento']=data_trainCopia['Descuento'].fillna(mode(data_trainCopia['Descuento']))\n",
    "\n",
    "data_testCopia['Nombre']=data_testCopia['Nombre'].fillna(mode(data_testCopia['Nombre']))\n",
    "data_testCopia['Año']=data_testCopia['Año'].fillna(mode(data_testCopia['Año']))\n",
    "data_testCopia['Ciudad']=data_testCopia['Ciudad'].fillna(mode(data_testCopia['Ciudad']))\n",
    "data_testCopia['Kilometros']=data_testCopia['Kilometros'].fillna(mode(data_testCopia['Kilometros']))\n",
    "data_testCopia['Combustible']=data_testCopia['Combustible'].fillna(mode(data_testCopia['Combustible']))\n",
    "data_testCopia['Tipo_marchas']=data_testCopia['Tipo_marchas'].fillna(mode(data_testCopia['Tipo_marchas']))\n",
    "data_testCopia['Mano']=data_testCopia['Mano'].fillna(mode(data_testCopia['Mano']))\n",
    "data_testCopia['Consumo']=data_testCopia['Consumo'].fillna(mode(data_testCopia['Consumo']))\n",
    "data_testCopia['Motor_CC']=data_testCopia['Motor_CC'].fillna(mode(data_testCopia['Motor_CC']))\n",
    "data_testCopia['Potencia']=data_testCopia['Potencia'].fillna(mode(data_testCopia['Potencia']))\n",
    "data_testCopia['Asientos']=data_testCopia['Asientos'].fillna(mode(data_testCopia['Asientos']))\n",
    "data_testCopia['Descuento']=data_testCopia['Descuento'].fillna(mode(data_testCopia['Descuento']))\n",
    "\n",
    "#Eliminamos las columnas que no necesitamos\n",
    "data_trainCopia=data_trainCopia.drop(['Descuento'], axis=1)\n",
    "data_trainCopia=data_trainCopia.drop(['id'], axis=1)\n",
    "data_testCopia=data_testCopia.drop(['Descuento'], axis=1)\n",
    "data_testCopia=data_testCopia.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "#Eliminamos los nan de los ids\n",
    "data_trainCopia=data_trainCopia.dropna() \n",
    "data_testCopia=data_testCopia.dropna() \n",
    "\n",
    "\n",
    "#Codificación de las filas\n",
    "data_trainCopia.Nombre = Nombre.transform(data_trainCopia.Nombre)\n",
    "data_trainCopia.Año = Año.transform(data_trainCopia.Año)\n",
    "data_trainCopia.Ciudad = Ciudad.transform(data_trainCopia.Ciudad)\n",
    "data_trainCopia.Combustible = Combustible.transform(data_trainCopia.Combustible)\n",
    "data_trainCopia.Mano = Mano.transform(data_trainCopia.Mano)\n",
    "data_trainCopia.Asientos = Asientos.transform(data_trainCopia.Asientos)\n",
    "data_trainCopia.Tipo_marchas = LabelEncoder().fit_transform(data_trainCopia.Tipo_marchas)\n",
    "#-------------------------------------------------------------------------------------------\n",
    "data_testCopia.Nombre = Nombre.transform(data_testCopia.Nombre)\n",
    "data_testCopia.Año = Año.transform(data_testCopia.Año)\n",
    "data_testCopia.Ciudad = Ciudad.transform(data_testCopia.Ciudad)\n",
    "data_testCopia.Combustible = Combustible.transform(data_testCopia.Combustible)\n",
    "data_testCopia.Mano = Mano.transform(data_testCopia.Mano)\n",
    "data_testCopia.Asientos = Asientos.transform(data_testCopia.Asientos)\n",
    "data_testCopia.Tipo_marchas = LabelEncoder().fit_transform(data_testCopia.Tipo_marchas)\n",
    "\n",
    "target = pd.read_csv('./datos/precio_cat.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trainCopia[\"Consumo\"]=data_trainCopia[\"Consumo\"].str.replace('kmpl','')\n",
    "data_trainCopia[\"Motor_CC\"]=data_trainCopia[\"Motor_CC\"].str.replace('CC','')\n",
    "data_trainCopia[\"Potencia\"]=data_trainCopia[\"Potencia\"].str.replace('bhp','')\n",
    "data_testCopia[\"Consumo\"]=data_testCopia[\"Consumo\"].str.replace('kmpl','')\n",
    "data_testCopia[\"Motor_CC\"]=data_testCopia[\"Motor_CC\"].str.replace('CC','')\n",
    "data_testCopia[\"Potencia\"]=data_testCopia[\"Potencia\"].str.replace('bhp','')\n",
    "\n",
    "target_train=data_trainCopia['Precio_cat']\n",
    "data_trainCopia=data_trainCopia.drop(['Precio_cat'], axis=1)\n",
    "\n",
    "data_trainCopia=data_trainCopia.astype(float)\n",
    "data_testCopia=data_testCopia.astype(float)\n",
    "\n",
    "data_testCopia_nor = (data_testCopia-data_trainCopia.mean(0))/data_trainCopia.std(0)\n",
    "data_trainCopia_nor = (data_trainCopia-data_trainCopia.mean(0))/data_trainCopia.std(0)\n",
    "\n",
    "atributos=data_trainCopia_nor[['Nombre', 'Año','Kilometros','Combustible','Tipo_marchas','Mano','Consumo','Motor_CC','Potencia', 'Asientos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada SIN MODELO 80.24040818590207\n",
      "Score Validacion Cruzada SIN MODELO [0.81052632 0.78210526 0.79873551 0.8061117  0.81454162]\n",
      "Score Validacion Cruzada CON MODELO 80.24040818590207\n",
      "Score Validacion Cruzada CON MODELO [0.81052632 0.78210526 0.79873551 0.8061117  0.81454162]\n"
     ]
    }
   ],
   "source": [
    "#Subida 40 (Sin etiqueta profesor), subida 41 (Con las etiquetas del profesor)\n",
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.06, objective='binary', n_estimators=350, \n",
    "                           n_jobs=2, num_leaves=10, max_depth=-1, seed=46000)\n",
    "\n",
    "scores = cross_val_score(lgbm1, data_trainCopia_nor, target_train, cv=5)\n",
    "print(\"Score Validacion Cruzada SIN MODELO\", np.mean(scores)*100)\n",
    "print(\"Score Validacion Cruzada SIN MODELO\", scores)\n",
    "\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia_nor, target_train)\n",
    "preLgb = lgbmEntrenado.predict(data_testCopia_nor)\n",
    "\n",
    "scores = cross_val_score(lgbmEntrenado, atributos, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada CON MODELO\", np.mean(scores)*100)\n",
    "print(\"Score Validacion Cruzada CON MODELO\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subida 42\n",
    "lgbm1 = lgb.LGBMClassifier(learning_rate=0.055, objective='binary', n_estimators=450, \n",
    "                           n_jobs=2, num_leaves=10, max_depth=-1, seed=46000)\n",
    "\n",
    "scores = cross_val_score(lgbm1, data_trainCopia_nor, target_train, cv=5)\n",
    "print(\"Score Validacion Cruzada SIN MODELO\", np.mean(scores)*100)\n",
    "print(\"Score Validacion Cruzada SIN MODELO\", scores)\n",
    "\n",
    "lgbmEntrenado = lgbm1.fit(data_trainCopia_nor, target_train)\n",
    "preLgb = lgbmEntrenado.predict(data_testCopia_nor)\n",
    "\n",
    "scores = cross_val_score(lgbmEntrenado, atributos, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada CON MODELO\", np.mean(scores)*100)\n",
    "print(\"Score Validacion Cruzada CON MODELO\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.055, n_estimators=750)\n",
    "clfEntrenado = clf.fit(data_trainCopia_nor, target_train)\n",
    "score = clf.score(data_trainCopia_nor, target_train)\n",
    "preclf = clfEntrenado.predict(data_testCopia_nor)\n",
    "\n",
    "scores = cross_val_score(clfEntrenado, atributos, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada\", np.mean(score)*100)\n",
    "print(\"Score Validacion Cruzada\", np.mean(scores)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada 82.57878098829792\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.055, n_estimators=700,max_depth=3, \n",
    "                                 min_samples_split=2, min_samples_leaf=1, random_state=10)\n",
    "\n",
    "\n",
    "\n",
    "clfEntrenado = clf.fit(data_trainCopia_nor, target_train)\n",
    "\n",
    "score = clf.score(data_trainCopia_nor, target_train)\n",
    "\n",
    "preclf = clfEntrenado.predict(data_testCopia_nor)\n",
    "\n",
    "scores = cross_val_score(clfEntrenado, atributos, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada\", np.mean(score)*100)\n",
    "print(\"Score Validacion Cruzada\", np.mean(scores)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada 83.69488103821197\n"
     ]
    }
   ],
   "source": [
    "classifier1 = lgb.LGBMClassifier(learning_rate=0.06, objective='binary', n_estimators=350, n_jobs=2, \n",
    "                          num_leaves=10, max_depth=-1,seed=46000)\n",
    "\n",
    "classifier2 = GradientBoostingClassifier(learning_rate=0.5, n_estimators=600)\n",
    "\n",
    "clf = StackingCVClassifier(classifiers = [classifier1, classifier2],\n",
    "                            shuffle = False,\n",
    "                            use_probas = True,\n",
    "                            cv = 5,\n",
    "                            meta_classifier = SVC(probability = True))\n",
    "    \n",
    "scores = cross_val_score(clf, data_trainCopia_nor, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada\", np.mean(scores)*100)\n",
    "\n",
    "clf2Entrenado = clf.fit(data_trainCopia_nor, target_train)\n",
    "preclf2 = clf2Entrenado.predict(data_testCopia_nor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAux = pd.DataFrame({'id':data_test['id']})\n",
    "dfAux.set_index('id', inplace=True)\n",
    "dfFinal = pd.DataFrame({'id': data_test['id'], 'Precio_cat': preclf2}, columns=['id', 'Precio_cat'])\n",
    "dfFinal.set_index('id', inplace=True)\n",
    "dfFinal.to_csv(\"./soluciones/datosNormalizadosConStackinLGBMyGradient.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada 83.63170095945873\n"
     ]
    }
   ],
   "source": [
    "classifier1 = lgb.LGBMClassifier(learning_rate=0.06, objective='binary', n_estimators=350, n_jobs=2, \n",
    "                          num_leaves=10, max_depth=-1,seed=46000)\n",
    "\n",
    "classifier2 = GradientBoostingClassifier(learning_rate=0.5, n_estimators=600)\n",
    "\n",
    "clf = StackingCVClassifier(classifiers = [classifier1, classifier2],\n",
    "                            shuffle = False,\n",
    "                            use_probas = True,\n",
    "                            cv = 5,\n",
    "                            meta_classifier = SVC(probability = True))\n",
    "    \n",
    "scores = cross_val_score(clf, data_trainCopia_nor, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada\", np.mean(scores)*100)\n",
    "\n",
    "clf2Entrenado = clf.fit(data_trainCopia_nor, target_train)\n",
    "preclf2 = clf2Entrenado.predict(data_testCopia_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion Cruzada 83.73725250956684\n"
     ]
    }
   ],
   "source": [
    "classifier1 = lgb.LGBMClassifier(learning_rate=0.06, objective='binary', n_estimators=350, n_jobs=2, \n",
    "                          num_leaves=10, max_depth=-1,seed=46000)\n",
    "\n",
    "classifier2 = GradientBoostingClassifier(learning_rate=0.55, n_estimators=550)\n",
    "\n",
    "clf = StackingCVClassifier(classifiers = [classifier1, classifier2],\n",
    "                            shuffle = False,\n",
    "                            use_probas = True,\n",
    "                            cv = 5,\n",
    "                            meta_classifier = SVC(probability = True))\n",
    "    \n",
    "scores = cross_val_score(clf, data_trainCopia_nor, target_train, cv=5, scoring='accuracy')\n",
    "print(\"Score Validacion Cruzada\", np.mean(scores)*100)\n",
    "\n",
    "clf3Entrenado = clf.fit(data_trainCopia_nor, target_train)\n",
    "preclf3 = clf3Entrenado.predict(data_testCopia_nor)\n",
    "\n",
    "dfAux = pd.DataFrame({'id':data_test['id']})\n",
    "dfAux.set_index('id', inplace=True)\n",
    "dfFinal = pd.DataFrame({'id': data_test['id'], 'Precio_cat': preclf3}, columns=['id', 'Precio_cat'])\n",
    "dfFinal.set_index('id', inplace=True)\n",
    "dfFinal.to_csv(\"./soluciones/datosNormalizadosConStackinLGBMyGradientMEJORADO8375.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
